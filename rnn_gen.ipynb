{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only z is quantized\n",
    "# for f0 and ld different heads in the rnn is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkl = tf.keras.layers\n",
    "\n",
    "seqlen = 1000\n",
    "dim_code = 18\n",
    "\n",
    "# RNN model with 3 heads\n",
    "inputs = tfkl.Input(batch_shape=(batch_size, None, dim_code))\n",
    "x = tfkl.GRU(512, return_sequences=True, stateful=True)(inputs)\n",
    "# x = tfkl.GRU(512, return_sequences=True, stateful=True)(x)\n",
    "x = tfkl.Dense(256, tf.nn.relu)(x) \n",
    "# 3 seperate output layers\n",
    "f0_output = tfkl.Dense(128)(x)\n",
    "ld_output = tfkl.Dense(121)(x)\n",
    "z_output = tfkl.Dense(64)(x)\n",
    "    \n",
    "model_rnn = tf.keras.Model(inputs=inputs, outputs=[f0_output, ld_output, z_output], name='Functional-api-RNN')\n",
    "\n",
    "train_steps = 200000\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "lr = tf.optimizers.schedules.PolynomialDecay(0.0003, train_steps, 0.00001)\n",
    "opt = tf.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(ind_batch, code_batch):\n",
    "    targets_f0 = tf.cast(code_batch[:, 1:, 0:1] * 127, tf.dtypes.int64) # 128 MIDI pitches for f0_scaled targets\n",
    "    targets_f0 = tf.reshape(targets_f0, [-1,seqlen-1])\n",
    "    targets_ld = ind_batch[:, 1:, 0:1] # this is loudness_db used as labels for ld_scaled\n",
    "    targets_ld = tf.reshape(targets_ld, [-1,seqlen-1]) * (-1) # sign of the label altered from '-' to '+'\n",
    "    targets_z = ind_batch[:, 1:, 1:]\n",
    "    targets_z = tf.reshape(targets_z, [-1,seqlen-1])\n",
    "    inp = code_batch[:, :-1]\n",
    "    with tf.GradientTape() as tape:\n",
    "        out = model_rnn(inp)\n",
    "        xent_f0 = loss(targets_f0, out[0])\n",
    "        xent_ld = loss(targets_ld, out[1])\n",
    "        xent_z = loss(targets_z, out[2])\n",
    "        xent = (xent_f0 + xent_ld + xent_z) / 3.\n",
    "    \n",
    "    grads = tape.gradient(xent, model_rnn.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model_rnn.trainable_variables))\n",
    "    return xent\n",
    "\n",
    "losses = []\n",
    "for st, (inds, codes) in enumerate(code_data_ready):\n",
    "    if st > train_steps:\n",
    "        break\n",
    "        \n",
    "    model_rnn.reset_states()\n",
    "    xent = train(inds, codes)\n",
    "    losses.append(xent)\n",
    "    if not st % 1000:\n",
    "        print(st, xent)\n",
    "losses = tf.concat(losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rnn():\n",
    "    model_rnn.reset_states()\n",
    "    gen_f0 = tf.convert_to_tensor(np.random.randint(128, size=(batch_size, 1)))\n",
    "    gen_f0 = tf.cast(tf.reshape(gen_f0/127, (batch_size, 1, 1)), tf.dtypes.float32)\n",
    "    gen_ld = tf.convert_to_tensor(np.random.randint(121, size=(batch_size, 1)))\n",
    "    gen_ld = tf.cast(tf.reshape((-gen_ld/120)+1, (batch_size, 1, 1)), tf.dtypes.float32) # (features['loudness_db'] / LD_RANGE) + 1.0\n",
    "    gen_z = tf.convert_to_tensor(np.random.randint(64, size=(batch_size, 1)))\n",
    "    gen_z = tf.gather(codebook, gen_z)\n",
    "    out = tf.concat((gen_f0, gen_ld, gen_z), axis=-1)\n",
    "    collected = [out] \n",
    "    for t in range(seqlen-1):\n",
    "        out = model_rnn(out)\n",
    "        gen_f0 = tfd.Categorical(logits=out[0]).sample()\n",
    "        gen_f0 = tf.cast(tf.reshape(gen_f0/127, (batch_size, 1, 1)), tf.dtypes.float32)\n",
    "        gen_ld = tfd.Categorical(logits=out[1]).sample()\n",
    "        gen_ld = tf.cast(tf.reshape((-gen_ld/120)+1, (batch_size, 1, 1)), tf.dtypes.float32)\n",
    "        gen_z = tfd.Categorical(logits=out[2]).sample()\n",
    "        gen_z = tf.gather(codebook, gen_z)\n",
    "        out = tf.concat((gen_f0, gen_ld, gen_z), axis=-1)\n",
    "        collected.append(out)\n",
    "    collected = tf.concat(collected, axis=1)\n",
    "    gen_f0, gen_ld, gen_z = tf.split(collected, [1,1,16], axis=-1)\n",
    "    return gen_f0, gen_ld, gen_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Audio\n",
    "\n",
    "fs, ld, z = generate_rnn()\n",
    "fh = fs*127\n",
    "fh = 2**((fh - 69) / 12) * 440\n",
    "\n",
    "back_to_decoder = {}\n",
    "back_to_decoder['f0_hz'] = fh\n",
    "back_to_decoder['f0_scaled'] = fs\n",
    "back_to_decoder['ld_scaled'] = ld\n",
    "back_to_decoder['z'] = z\n",
    "\n",
    "audio_gen = model_vq.decode(back_to_decoder)\n",
    "# some audio_gen outputs are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "vqvae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
